{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model_pytorch import LMModel, load_openai_pretrained_model\n",
    "from text_utils import TextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40478"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab + n_special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(X):\n",
    "    X = np.array(X)\n",
    "    assert X.ndim in [1, 2]\n",
    "    if X.ndim == 1:\n",
    "        X = np.expand_dims(X, axis=0)\n",
    "    pos_enc = np.arange(n_vocab + n_special, n_vocab + n_special + X.shape[-1])\n",
    "    pos_enc = np.expand_dims(pos_enc, axis=0)\n",
    "    batch = np.stack([X, pos_enc], axis=-1)\n",
    "    batch = torch.tensor(batch, dtype=torch.long).to(device)\n",
    "    return batch\n",
    "\n",
    "def append_batch(X, next_idx):\n",
    "    next_pos = X[:, -1:, 1] + 1\n",
    "    next_x = torch.cat((next_idx, next_pos), -1).unsqueeze(1)\n",
    "    return torch.cat((X, next_x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(afn='gelu', analysis=False, attn_pdrop=0.1, b1=0.9, b2=0.999, bpe_path='model/vocab_40000.bpe', clf_pdrop=0.1, data_dir='data/', dataset=None, desc=None, e=1e-08, embd_pdrop=0.1, encoder_path='model/encoder_bpe_40000.json', gen_len=20, l2=0.01, lm_coef=0.5, log_dir='log/', lr=6.25e-05, lr_schedule='warmup_linear', lr_warmup=0.002, max_grad_norm=1, n_batch=8, n_ctx=512, n_embd=768, n_head=12, n_iter=3, n_layer=12, n_transfer=12, n_valid=374, opt='adam', resid_pdrop=0.1, save_dir='save/', seed=42, submission_dir='submission/', submit=False, topk=10, vector_l2=False)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--desc', type=str, help=\"Description\")\n",
    "parser.add_argument('--dataset', type=str)\n",
    "parser.add_argument('--log_dir', type=str, default='log/')\n",
    "parser.add_argument('--save_dir', type=str, default='save/')\n",
    "parser.add_argument('--data_dir', type=str, default='data/')\n",
    "parser.add_argument('--submission_dir', type=str, default='submission/')\n",
    "parser.add_argument('--submit', action='store_true')\n",
    "parser.add_argument('--analysis', action='store_true')\n",
    "parser.add_argument('--seed', type=int, default=42)\n",
    "parser.add_argument('--n_iter', type=int, default=3)\n",
    "parser.add_argument('--n_batch', type=int, default=8)\n",
    "parser.add_argument('--max_grad_norm', type=int, default=1)\n",
    "parser.add_argument('--lr', type=float, default=6.25e-5)\n",
    "parser.add_argument('--lr_warmup', type=float, default=0.002)\n",
    "parser.add_argument('--n_ctx', type=int, default=512)\n",
    "parser.add_argument('--n_embd', type=int, default=768)\n",
    "parser.add_argument('--n_head', type=int, default=12)\n",
    "parser.add_argument('--n_layer', type=int, default=12)\n",
    "parser.add_argument('--embd_pdrop', type=float, default=0.1)\n",
    "parser.add_argument('--attn_pdrop', type=float, default=0.1)\n",
    "parser.add_argument('--resid_pdrop', type=float, default=0.1)\n",
    "parser.add_argument('--clf_pdrop', type=float, default=0.1)\n",
    "parser.add_argument('--l2', type=float, default=0.01)\n",
    "parser.add_argument('--vector_l2', action='store_true')\n",
    "parser.add_argument('--opt', type=str, default='adam')\n",
    "parser.add_argument('--afn', type=str, default='gelu')\n",
    "parser.add_argument('--lr_schedule', type=str, default='warmup_linear')\n",
    "parser.add_argument('--encoder_path', type=str, default='model/encoder_bpe_40000.json')\n",
    "parser.add_argument('--bpe_path', type=str, default='model/vocab_40000.bpe')\n",
    "parser.add_argument('--n_transfer', type=int, default=12)\n",
    "parser.add_argument('--lm_coef', type=float, default=0.5)\n",
    "parser.add_argument('--b1', type=float, default=0.9)\n",
    "parser.add_argument('--b2', type=float, default=0.999)\n",
    "parser.add_argument('--e', type=float, default=1e-8)\n",
    "parser.add_argument('--n_valid', type=int, default=374)\n",
    "parser.add_argument('--gen_len', type=int, default=20)\n",
    "parser.add_argument('--topk', type=int, default=10)\n",
    "\n",
    "args = parser.parse_args([])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda n_gpu 1\n",
      "Loading weights...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LMModel(\n",
       "  (transformer): TransformerModel(\n",
       "    (embed): Embedding(40990, 768)\n",
       "    (drop): Dropout(p=0.1)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1)\n",
       "          (resid_dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): LMHead(\n",
       "    (decoder): Linear(in_features=768, out_features=40990, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "# Constants\n",
    "submit = args.submit\n",
    "dataset = args.dataset\n",
    "n_ctx = args.n_ctx\n",
    "save_dir = args.save_dir\n",
    "desc = args.desc\n",
    "data_dir = args.data_dir\n",
    "log_dir = args.log_dir\n",
    "submission_dir = args.submission_dir\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(\"device\", device, \"n_gpu\", n_gpu)\n",
    "\n",
    "text_encoder = TextEncoder(args.encoder_path, args.bpe_path)\n",
    "encoder = text_encoder.encoder\n",
    "n_vocab = len(text_encoder.encoder)\n",
    "\n",
    "n_special = 0   # XD: useless for language modeling task\n",
    "vocab = n_vocab + n_special + n_ctx\n",
    "\n",
    "lm_model = LMModel(args, vocab, n_ctx, return_probs=True)\n",
    "load_openai_pretrained_model(lm_model.transformer, n_ctx=n_ctx, n_special=n_special)\n",
    "lm_model.to(device)\n",
    "\n",
    "lm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# text = 'Hello, here is a sentence so I can test out what actually gets input into the linear model'\n",
    "text = 'What the hell is this thing that we call positional encoding'\n",
    "X = text_encoder.encode([text,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "XMB = make_batch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  599, 40478],\n",
       "         [  481, 40479],\n",
       "         [ 1491, 40480],\n",
       "         [  544, 40481],\n",
       "         [  616, 40482],\n",
       "         [  615, 40483],\n",
       "         [  525, 40484],\n",
       "         [  606, 40485],\n",
       "         [ 1370, 40486],\n",
       "         [ 3589, 40487],\n",
       "         [ 1586, 40488],\n",
       "         [  496, 40489],\n",
       "         [33927, 40490]]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3570, 40478],\n",
       "         [  240, 40479],\n",
       "         [  793, 40480],\n",
       "         [  544, 40481],\n",
       "         [  246, 40482],\n",
       "         [ 5958, 40483],\n",
       "         [  620, 40484],\n",
       "         [  249, 40485],\n",
       "         [  759, 40486],\n",
       "         [ 2345, 40487],\n",
       "         [  551, 40488],\n",
       "         [  599, 40489],\n",
       "         [ 1629, 40490],\n",
       "         [ 2694, 40491],\n",
       "         [19449, 40492],\n",
       "         [  666, 40493],\n",
       "         [  481, 40494],\n",
       "         [35422, 40495],\n",
       "         [ 7129, 40496]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda n_gpu 1\n",
      "Loading weights...\n",
      "Input some beginning words:Hello there\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". it 's a long story . \" \n",
      " the woman sighed . \" i can help you with that \n",
      "Input some beginning words:Wow this is pretty coolio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", ' said granny , who 'd got on to the old man 's back . ' how come you \n",
      "Input some beginning words:quit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". she did n't know how to react , but he seemed to be the most confident man that she \n",
      "Input some beginning words:ii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", the world is in chaos , the people are dying and the people are dying , and the only \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/musical_neural_net/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/musical_neural_net/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/musical_neural_net/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/musical_neural_net/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ec7598469ec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input some beginning words:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/musical_neural_net/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/musical_neural_net/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = input('Input some beginning words:')\n",
    "while text != 'q':\n",
    "    X = text_encoder.encode([text,])\n",
    "    XMB = make_batch(X)\n",
    "\n",
    "    for _ in range(args.gen_len):\n",
    "        lm_probs = lm_model(XMB)\n",
    "        if args.topk == 0:\n",
    "            next_idx = torch.multinomial(lm_probs[:, -1, :], 1)\n",
    "        else:\n",
    "            values, indices = lm_probs[:, -1, :].topk(args.topk)\n",
    "            next_idx = indices.gather(-1, torch.multinomial(values, 1))\n",
    "        next_token = text_encoder.decoder[next_idx.item()].replace('</w>', '')\n",
    "        print(next_token, end=' ')\n",
    "        XMB = append_batch(XMB, next_idx)\n",
    "\n",
    "    print()\n",
    "    text = input('Input some beginning words:')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
